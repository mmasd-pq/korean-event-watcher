# debug_scraper.py - ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import logging
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import json

# ã‚ãªãŸã® config.py ã®è¨­å®šã‚’ç›´æ¥ã“ã“ã«å«ã‚ã‚‹
TARGET_URLS = [
    # --- æ˜ ç”»é¤¨ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆå‘ŠçŸ¥ãŒå®‰å®šã—ã¦æ²è¼‰ã•ã‚Œã‚‹ï¼‰ ---
    {
        "name": "MEGABOX ã‚¤ãƒ™ãƒ³ãƒˆ",
        "url": "https://www.megabox.co.kr/event",
        # ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§â†’å„è©³ç´°ã¸ã®ãƒªãƒ³ã‚¯ãŒ <a href="/event/detail?...">
        "selector": "a[href*='/event/detail']",
        "base_url": "https://www.megabox.co.kr"
    },
    {
        "name": "CGV ã‚¤ãƒ™ãƒ³ãƒˆ",
        "url": "https://www.cgv.co.kr/culture-event/event/",
        # ãƒªã‚¹ãƒˆã® HTML ã¯ãŸã³ãŸã³å¤‰ã‚ã‚‹ã®ã§ a ã‚’åºƒã‚ã«
        "selector": "a[href*='/culture-event/event/'], a[href*='detailViewUnited.aspx']",
        "base_url": "https://www.cgv.co.kr"
    },
    {
        "name": "LOTTE CINEMA ã‚¤ãƒ™ãƒ³ãƒˆ",
        "url": "https://www.lottecinema.co.kr/LCWS/Event/EventList.aspx",
        "selector": "a[href*='EventDetail'], .event-item a",
        "base_url": "https://www.lottecinema.co.kr"
    },
    {
        "name": "HYBE Pressï¼ˆè‹±èªï¼‰",
        "url": "https://hybecorp.com/eng/news/news",
        "selector": ".news_list li a, .list li a, a[href*='/eng/news/news/']",
        "base_url": "https://hybecorp.com"
    },
    {
        "name": "HYBE Noticeï¼ˆè‹±èªï¼‰",
        "url": "https://hybecorp.com/eng/news/notice",
        "selector": ".news_list li a, .list li a, a[href*='/eng/news/notice/']",
        "base_url": "https://hybecorp.com"
    },
    {
        "name": "SM Entertainment NEWS",
        "url": "https://www.smentertainment.com/News",
        "selector": ".news_list li a, .list li a, a[href*='/News/']",
        "base_url": "https://www.smentertainment.com"
    }
]

def debug_site(site_config):
    """
    ç‰¹å®šã‚µã‚¤ãƒˆã®HTMLæ§‹é€ ã‚’è©³ç´°ã«èª¿æŸ»ã™ã‚‹ãƒ‡ãƒãƒƒã‚°é–¢æ•°
    """
    name = site_config.get("name", "Unknown")
    url = site_config.get("url", "")
    selector = site_config.get("selector", "")
    
    print(f"\n{'='*60}")
    print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°ä¸­: {name}")
    print(f"URL: {url}")
    print(f"ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼: {selector}")
    print(f"{'='*60}")
    
    if not url:
        print("âŒ URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    try:
        # HTMLå–å¾—
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/115.0.0.0 Safari/537.36"
            )
        }
        
        print(f"ğŸ“¡ HTMLã‚’å–å¾—ä¸­...")
        resp = requests.get(url, headers=headers, timeout=15)
        resp.raise_for_status()
        print(f"âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {resp.status_code}")
        print(f"ğŸ“„ HTMLã‚µã‚¤ã‚º: {len(resp.text)} æ–‡å­—")
        
        soup = BeautifulSoup(resp.text, "html.parser")
        
        # ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã®è¦ç´ æ¤œç´¢
        if selector:
            elements = soup.select(selector)
            print(f"ğŸ¯ ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ '{selector}' ã§è¦‹ã¤ã‹ã£ãŸè¦ç´ : {len(elements)}å€‹")
            
            if elements:
                print(f"\nğŸ“ æœ€åˆã®3è¦ç´ ã®è©³ç´°:")
                for i, el in enumerate(elements[:3]):
                    print(f"\n--- è¦ç´  {i+1} ---")
                    print(f"ã‚¿ã‚°å: {el.name}")
                    print(f"ã‚¯ãƒ©ã‚¹: {el.get('class', [])}")
                    print(f"ID: {el.get('id', 'ãªã—')}")
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
                    text = el.get_text(strip=True)[:100]
                    print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {text}...")
                    
                    # ãƒªãƒ³ã‚¯
                    link = el.find("a")
                    if link:
                        href = link.get("href", "")
                        print(f"ãƒªãƒ³ã‚¯: {href}")
                    else:
                        print("ãƒªãƒ³ã‚¯: ãªã—")
            else:
                # ä»£æ›¿ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’ææ¡ˆ
                print(f"\nğŸ’¡ ä»£æ›¿ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼å€™è£œ:")
                suggest_selectors(soup)
        else:
            print("âš ï¸ ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            suggest_selectors(soup)
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

def suggest_selectors(soup):
    """HTMLæ§‹é€ ã‚’åˆ†æã—ã¦é©åˆ‡ãªã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ã‚’ææ¡ˆ"""
    suggestions = []
    
    # ã‚ˆãã‚ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆç³»ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼å€™è£œ
    candidates = [
        (".event", "ã‚¤ãƒ™ãƒ³ãƒˆé–¢é€£ã®ã‚¯ãƒ©ã‚¹"),
        (".news", "ãƒ‹ãƒ¥ãƒ¼ã‚¹é–¢é€£ã®ã‚¯ãƒ©ã‚¹"), 
        (".item", "ã‚¢ã‚¤ãƒ†ãƒ ç³»ã®ã‚¯ãƒ©ã‚¹"),
        (".post", "æŠ•ç¨¿ç³»ã®ã‚¯ãƒ©ã‚¹"),
        (".article", "è¨˜äº‹ç³»ã®ã‚¯ãƒ©ã‚¹"),
        ("article", "articleã‚¿ã‚°"),
        (".list-item", "ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ "),
        (".content-item", "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¢ã‚¤ãƒ†ãƒ "),
        ("li", "ãƒªã‚¹ãƒˆè¦ç´ "),
        ("h2", "è¦‹å‡ºã—2"),
        ("h3", "è¦‹å‡ºã—3"),
    ]
    
    print("\nğŸ” ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼å€™è£œ:")
    for selector, desc in candidates:
        elements = soup.select(selector)
        if elements:
            print(f"  {selector:15} â†’ {len(elements):3d}å€‹ ({desc})")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
            if elements[0]:
                sample_text = elements[0].get_text(strip=True)[:50]
                print(f"      ä¾‹: {sample_text}...")

def debug_current_config():
    """ç¾åœ¨ã®è¨­å®šã§ãƒ‡ãƒãƒƒã‚°ã‚’å®Ÿè¡Œ"""
    print(f"ğŸ¯ è¨­å®šã•ã‚Œã¦ã„ã‚‹ã‚µã‚¤ãƒˆæ•°: {len(TARGET_URLS)}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é¸æŠã•ã›ã‚‹
    print("\nğŸ“‹ ãƒ‡ãƒãƒƒã‚°ã—ãŸã„ã‚µã‚¤ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:")
    for i, site in enumerate(TARGET_URLS):
        name = site.get("name", f"ã‚µã‚¤ãƒˆ{i+1}")
        print(f"  {i+1}: {name}")
    
    print(f"  0: ã™ã¹ã¦")
    print(f"  99: å•é¡Œã®ã‚ã‚‹ã‚µã‚¤ãƒˆã®ã¿ï¼ˆ0ä»¶ã®ã‚µã‚¤ãƒˆï¼‰")
    
    try:
        choice = input("\nç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
        
        if choice == "0":
            for site in TARGET_URLS:
                debug_site(site)
        elif choice == "99":
            # 0ä»¶ã ã£ãŸã‚µã‚¤ãƒˆã®ã¿ã‚’ãƒã‚§ãƒƒã‚¯
            problem_sites = [
                TARGET_URLS[0],  # MEGABOX
                TARGET_URLS[1],  # CGV  
                TARGET_URLS[2],  # LOTTE CINEMA
            ]
            for site in problem_sites:
                debug_site(site)
        else:
            idx = int(choice) - 1
            if 0 <= idx < len(TARGET_URLS):
                debug_site(TARGET_URLS[idx])
            else:
                print("âŒ ç„¡åŠ¹ãªç•ªå·ã§ã™")
    except ValueError:
        print("âŒ æ•°å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ãƒ‡ãƒãƒƒã‚°ã‚’çµ‚äº†ã—ã¾ã™")

def manual_debug():
    """æ‰‹å‹•ã§ã‚µã‚¤ãƒˆæƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãƒ‡ãƒãƒƒã‚°"""
    url = input("ãƒ‡ãƒãƒƒã‚°ã—ãŸã„URL: ").strip()
    selector = input("ç¾åœ¨ã®ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼ (ç©ºç™½ã§ã‚¹ã‚­ãƒƒãƒ—): ").strip()
    
    site_config = {
        "name": "æ‰‹å‹•å…¥åŠ›ã‚µã‚¤ãƒˆ",
        "url": url,
        "selector": selector if selector else None
    }
    
    debug_site(site_config)

if __name__ == "__main__":
    print("ğŸ”§ éŸ“å›½ã‚¤ãƒ™ãƒ³ãƒˆã‚¦ã‚©ãƒƒãƒãƒ£ãƒ¼ ãƒ‡ãƒãƒƒã‚°ãƒ„ãƒ¼ãƒ«")
    debug_current_config()
